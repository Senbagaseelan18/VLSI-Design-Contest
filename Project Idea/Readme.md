<div align="center">

  <h1>💡 Project Idea — EdgeSight</h1>
  
  <p>
    <b>EdgeSight:</b> An FPGA-Accelerated AI Assistive Device for the Visually Impaired  
    using <b>PolarFire® SoC FPGA</b> Platform 2.
  </p>

  <a href="https://www.microchip.com/" target="_blank">
    <img src="../Tool Installation & Setup Guide/Images/mic.png" width="200" alt="Microchip Technology logo">
  </a>

  <br><br>
  <img src="https://img.shields.io/badge/Project-EdgeSight_AI_Assistive_Device-green?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Platform-PolarFire®_SoC-red?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Focus-Vision_&_Navigation-blue?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Type-Wearable_Device-orange?style=for-the-badge" />

</div>

---

# 📘 Table of Contents

| 🔢 # | 📂 Topic | 🔗 Link |
|------|----------|---------|
| 1 | **Abstract** | [Jump to Section](#1-abstract) |
| 2 | **Core Processing** | [Jump to Section](#2-core-processing) |
| 3 | **Vision & Perception** | [Jump to Section](#3-vision--perception) |
| 4 | **Audio & User Interaction** | [Jump to Section](#4-audio--user-interaction) |
| 5 | **Text, Currency & Face Recognition** | [Jump to Section](#5-text-currency--face-recognition) |
| 6 | **Location & Navigation** | [Jump to Section](#6-location--navigation) |
| 7 | **Connectivity & Mobile Dashboard** | [Jump to Section](#7-connectivity--mobile-dashboard) |
| 8 | **Enclosure & Mounting** | [Jump to Section](#8-enclosure--mounting) |
| 9 | **Applications** | [Jump to Section](#9-applications) |
| 10 | **Value Add** | [Jump to Section](#10-value-add) |
| 11 | **References** | [Jump to Section](#11-references) |
| 12 | **Full Document** | [Download PDF](./EdgeSight_Project_Idea.pdf) |

---

## 📝 1. Abstract

EdgeSight is a wearable assistive device powered by the **PolarFire® SoC FPGA**, designed to help visually impaired individuals perceive their surroundings through AI-driven vision and natural voice guidance.  
Unlike cloud-based solutions, EdgeSight operates fully offline, ensuring privacy, reliability, and low power consumption.

---

## 🧩 2. Core Processing

- **PolarFire® SoC FPGA** – FPGA fabric accelerates vision tasks; RISC-V subsystem runs Linux/RTOS for control, chatbot, and user services.  
- **Onboard DDR3/DDR4/LPDDR4 Memory** – supports AI models, OCR, and data buffering.

---

## 👁️ 3. Vision & Perception

- **MIPI CSI Camera** – captures live video for object detection and OCR.  
- **Ultrasonic / LiDAR** – enhances obstacle detection.  
- **FPGA-Accelerated AI Models** – real-time detection and recognition.  
- **Contextual Awareness** – describes objects with location cues (e.g., “Phone is on the table ahead”).  

EdgeSight detects objects, reads text, recognizes currency, identifies faces, and provides real-time voice/haptic guidance.

---

## 🔊 4. Audio & User Interaction

- **I²S Audio + Microphone Array** – supports wake word and commands.  
- **Offline Voice Assistant & AI Chatbot** – natural interaction without internet.  
- **Bone-Conduction Headset** – delivers spoken feedback safely.  
- **Haptic Motors** – vibration alerts for urgent warnings.

---

## 📄 5. Text, Currency & Face Recognition

- **OCR** – reads text from books, signs, labels.  
- **Currency Recognition** – identifies denominations.  
- **Face Recognition** – alerts when familiar people are nearby.

---

## 🗺️ 6. Location & Navigation

- **GPS Module** – provides real-time location and spoken updates.  
- **Navigation Guidance** – step-by-step voice + haptic feedback.  
- **SOS Mode** – shares location with trusted contacts.

---

## 📡 7. Connectivity & Mobile Dashboard

- **Bluetooth Module** – links to smartphone.  
- **LTE/4G** – standalone emergency messaging.  
- **Mobile Dashboard App** – shows device status and caregiver interface.

---

## 🏠 8. Enclosure & Mounting

- **Lightweight Wearable Housing** – chest, belt, or glasses mount.  
- **Water-Resistant (IP54+)** – outdoor ready.  
- **Straps/Clips** – for secure and comfortable use.

---

## 🚀 9. Applications

- **Assistive Technology** – Object detection, obstacle avoidance, text/currency reading, face recognition.  
- **Smart Mobility & Navigation** – GPS-based location updates, SOS alerts, safe navigation.  
- **Healthcare & Elderly Support** – Safety alerts, reminders, companion interaction.  
- **Education & Workplace Inclusion** – Access to printed text, labels, colleague recognition.  
- **Future Extensions** – Indoor navigation (BLE/SLAM), smart home integration, advanced AI models, caregiver monitoring.

---

## 💎 10. Value Add

- Fully Offline Operation – privacy, reliability, independence.  
- FPGA Acceleration – real-time AI inference, low power.  
- Multimodal Feedback – voice, haptic, contextual scene summaries.  
- AI Chatbot Integration – natural interaction.  
- Context-Aware Perception – spatial descriptions of objects.  
- Mobile Dashboard Support – remote monitoring, caregiver functionality.  
- Scalable & Secure – PolarFire® SoC FPGA hardware root-of-trust.  
- Novel Combination – computer vision, navigation, voice assistant, IoT in one wearable.

---

## 📚 11. References

1. Saini, Munish, and Eshan Sengupta. "Artificial intelligence inspired fog-cloud-based visual-assistance framework for blind and visually-impaired people." *Multimedia Tools and Applications* (2024): 1-32.  
2. Lima, Rui, et al. "Visually impaired people positioning assistance system using artificial intelligence." *IEEE Sensors Journal* 23.7 (2023): 7758-7765.  
3. Satani, Nirav, Smit Patel, and Sandip Patel. "AI powered glasses for visually impaired person." *International Journal of Recent Technology and Engineering (IJRTE)* 9.2 (2020): 416-421.

---

## 📄 12. Full Document

For detailed implementation and diagrams, download the full project document here:  
[EdgeSight_Project_Idea.pdf](./EdgeSight_Project_Idea.pdf)

---


**© 2025 VLSI Design Contest – EdgeSight Project Team**  
**Powered by Microchip PolarFire® SoC Technology**

</div>


